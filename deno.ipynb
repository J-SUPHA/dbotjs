{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import { ChromaClient } from \"npm:chromadb\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "const client = new ChromaClient();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "const collection = await client.getCollection({ name: \"dbot\" });\n",
    "\n",
    "\n",
    "\n",
    "// query the collectoin\n",
    "const data = await collection.get({\n",
    "  where: { channelId: \"1048378429231337493\" },\n",
    "  whereDocument: { $contains: \"idk i need to see if its a string or an int\" },\n",
    "  limit: 5,\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"idk i need to see if its a string or an int\"\u001b[39m"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  avatar: \u001b[32m\"1e8e57c550c23b5694cba2e0b24dc00a\"\u001b[39m,\n",
       "  channelId: \u001b[32m\"1048378429231337493\"\u001b[39m,\n",
       "  createdTimestamp: \u001b[33m1715027356047\u001b[39m,\n",
       "  discriminator: \u001b[32m\"6138\"\u001b[39m,\n",
       "  id: \u001b[32m\"1237139140575891586\"\u001b[39m,\n",
       "  source: \u001b[32m\"discord\"\u001b[39m,\n",
       "  tts: \u001b[33mfalse\u001b[39m,\n",
       "  type: \u001b[32m\"message\"\u001b[39m,\n",
       "  userId: \u001b[32m\"832295538128060458\"\u001b[39m,\n",
       "  username: \u001b[32m\"Tensor\"\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metadatas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const dataArray = Object.values(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "function formatMessages(data) {\n",
    "  if (!Array.isArray(data.metadatas) || data.metadatas.length === 0) {\n",
    "    console.error(\"No metadata available to process.\");\n",
    "    return ''; // Return an empty string or handle the error appropriately\n",
    "  }\n",
    "\n",
    "  if (!Array.isArray(data.documents) || data.documents.length === 0) {\n",
    "    console.error(\"No documents available to process.\");\n",
    "    return ''; // Return an empty string or handle the error appropriately\n",
    "  }\n",
    "\n",
    "  // Sort the metadatas array by createdTimestamp\n",
    "  data.metadatas.sort((a, b) => a.createdTimestamp - b.createdTimestamp);\n",
    "\n",
    "  // Map each metadata to a formatted string using the corresponding document and join them with newlines\n",
    "  return data.metadatas.map((meta, index) => {\n",
    "    const messageContent = data.documents[index] ? data.documents[index] : \"No content\";\n",
    "    return `${meta.username}: ${messageContent}`;\n",
    "  }).join('\\n');\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: Ah, Ah, my nigga! You got me again! Yeah, I can see our previous messages, and I can use that context to respond to your current message. I don't have personal memory, but I can access the conversation history and use it to inform my responses. So, while I don't have traditional memory, I can still use the conversation context to make my responses more relevant and engaging!\n",
      "Tensor: Alright, my nigga, I'm locking in. I'll put on my serious face and focus. No more jokes or playful banter. I'm all ears and ready to help you with whatever you need. Go ahead and share what's on your mind, and I'll do my best to provide helpful and thoughtful responses.\n"
     ]
    }
   ],
   "source": [
    "console.log(formatMessages(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
