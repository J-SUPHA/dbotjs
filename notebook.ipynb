{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "\n",
    "def get_last_x_messages(db_path: str, channel_id: int, k: int, channel_type: str) -> List[Dict]:\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Determine the query based on channel type\n",
    "    if channel_type == \"dm\":\n",
    "        query = \"\"\"\n",
    "        SELECT name, clean_content FROM (\n",
    "            SELECT COALESCE(global_name, user_name) AS name, clean_content, created_timestamp\n",
    "            FROM dms\n",
    "            WHERE channel_id = ?\n",
    "            ORDER BY created_timestamp DESC\n",
    "            LIMIT ?\n",
    "        ) sub ORDER BY created_timestamp ASC\n",
    "        \"\"\"\n",
    "    elif channel_type == \"channel\":\n",
    "        query = \"\"\"\n",
    "        SELECT name, clean_content FROM (\n",
    "            SELECT COALESCE(global_name, user_name) AS name, clean_content, created_timestamp\n",
    "            FROM messages\n",
    "            WHERE channel_id = ?\n",
    "            ORDER BY created_timestamp DESC\n",
    "            LIMIT ?\n",
    "        ) sub ORDER BY created_timestamp ASC\n",
    "        \"\"\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid channel type\")\n",
    "\n",
    "    # Execute the query and fetch the results\n",
    "    try:\n",
    "        cursor.execute(query, (channel_id, k))\n",
    "        rows = cursor.fetchall()\n",
    "        messages = [{'name': row[0], 'clean_content': row[1]} for row in rows]\n",
    "        return messages\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error fetching messages for {channel_type} with channel ID {channel_id}: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Ensure the database connection is closed after operation\n",
    "        conn.close()\n",
    "\n",
<<<<<<< Updated upstream
    "# Example usage:\n"
=======
    "# Example usage:\n",
    "db_path = 'messages.db'\n",
    "channel_id=1228090209825063002\n",
    "messages = get_last_x_messages(db_path, channel_id=channel_id, k=999, channel_type='channel')\n",
    "\n",
    "with open(f'{channel_id}.txt', encoding='utf-8', mode='a') as f:\n",
    "    for message in messages:\n",
    "        f.write(message + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_x_messages(db_path: str, channel_id: int, k: int, channel_type: str) -> List[Dict]:\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Determine the query based on channel type\n",
    "    if channel_type == \"dm\":\n",
    "        table = \"dms\"\n",
    "    elif channel_type == \"channel\":\n",
    "        table = \"messages\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid channel type\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT user_name AS name, clean_content FROM (\n",
    "        SELECT user_name, clean_content, created_timestamp\n",
    "        FROM {table}\n",
    "        WHERE channel_id = ?\n",
    "        ORDER BY created_timestamp DESC\n",
    "        LIMIT ?\n",
    "    ) sub ORDER BY created_timestamp ASC\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query and fetch the results\n",
    "    cursor.execute(query, (channel_id, k))\n",
    "    rows = cursor.fetchall()\n",
    "    messages = [{'name': row[0], 'clean_content': row[1]} for row in rows]\n",
    "    conn.close()\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'messages.db'\n",
    "channel_id = 1228090209825063002\n",
    "messages = get_last_x_messages(db_path, channel_id=channel_id, k=20, channel_type='channel')\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_columns(db_path, table_name):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return columns\n",
    "\n",
    "# Example usage to check columns of the 'messages' table\n",
    "columns = get_table_columns('messages.db', 'messages')\n",
    "print(columns)\n"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Document:\n",
    "    page_content: str\n",
    "    metadata: dict\n",
    "\n",
    "def get_last_x_messages(db_path: str, channel_id: int, k: int, channel_type: str) -> Document:\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Determine the query based on channel type\n",
    "    if channel_type == \"dm\":\n",
    "        query = \"\"\"\n",
    "        SELECT name, clean_content FROM (\n",
    "            SELECT COALESCE(global_name, user_name) AS name, clean_content, created_timestamp\n",
    "            FROM dms\n",
    "            WHERE channel_id = ?\n",
    "            ORDER BY created_timestamp DESC\n",
    "            LIMIT ?\n",
    "        ) sub ORDER BY created_timestamp ASC\n",
    "        \"\"\"\n",
    "    elif channel_type == \"channel\":\n",
    "        query = \"\"\"\n",
    "        SELECT name, clean_content FROM (\n",
    "            SELECT COALESCE(global_name, user_name) AS name, clean_content, created_timestamp\n",
    "            FROM messages\n",
    "            WHERE channel_id = ?\n",
    "            ORDER BY created_timestamp DESC\n",
    "            LIMIT ?\n",
    "        ) sub ORDER BY created_timestamp ASC\n",
    "        \"\"\"\n",
    "    else:\n",
    "        conn.close()  # Close the connection before raising the exception\n",
    "        raise ValueError(\"Invalid channel type\")\n",
    "    \n",
    "    # Execute the query\n",
    "    cursor.execute(query, (channel_id, k))\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Build the page content and metadata\n",
    "    page_content = '\\n'.join(f\"{name}: {content}\" for name, content in rows)\n",
    "    metadata = {'channel_id': channel_id, 'channel_type': channel_type}\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    # Return the constructed Document\n",
    "    return Document(page_content=page_content, metadata=metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'messages.db'\n",
    "messages = get_last_x_messages(db_path, channel_id=1048378429231337493, k=10, channel_type='dm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# turns the list of dicts in to a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def format_messages(messages: List[Dict]) -> str:\n",
    "    # Initialize an empty string to accumulate messages\n",
    "    formatted_string = \"\"\n",
    "    \n",
    "    # Iterate over each message in the list\n",
    "    for message in messages:\n",
    "        # Append each message's name and content to the formatted string\n",
    "        formatted_string += f\"{message['name']}: {message['clean_content']}<BREAK>\"\n",
    "    \n",
    "    return formatted_string\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_messages = format_messages(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(formatted_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def post_completion(prompt):\n",
    "    url = 'http://47.189.140.220:5001/v1/completions'\n",
    "    post_data = {\n",
    "        \"prompt\": f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\"Review the following conversation excerpts and extract key information that can be useful for understanding ongoing context, preferences, or notable mentions that Tensor should remember about the person for future interactions. Please format the extracted data in a structured format if possible. Ensure the information is ready to be used as is, without any introduction or starting preamble.\n",
    "Example:\n",
    "**Summary:**\n",
    "- Brief Summary of the conversation.\n",
    "\n",
    "**John's Music Preferences:**\n",
    "- Details about John's music preferences as were discussed in the conversation.\n",
    "\n",
    "\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "{prompt}\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.5,\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "\n",
    "    }\n",
    "    \n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(post_data))\n",
    "    response.raise_for_status()  # This will raise an exception for HTTP errors\n",
    "    data = response.json()\n",
    "\n",
    "    return data['choices'][0]['text']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = post_completion(formatted_messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "ollama = Ollama(\n",
    "    base_url='http://localhost:11434',\n",
    "    model=\"llama3\"\n",
    ")\n",
    "print(ollama.invoke(\"why is the sky blue\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain supports many other chat models. Here, we're using Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# supports many more optional parameters. Hover on your `ChatOllama(...)`\n",
    "# class to view the latest available supported parameters\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
    "\n",
    "# using LangChain Expressive Language chain syntax\n",
    "# learn more about the LCEL on\n",
    "# /docs/expression_language/why\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# for brevity, response is printed in terminal\n",
    "# You can use LangServe to deploy your application for\n",
    "# production\n",
    "print(chain.invoke({\"topic\": \"Space travel\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri('sqlite:///messages.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "def get_text_chunks_langchain(text):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=2000)\n",
    "    docs = [Document(page_content=x) for x in text_splitter.split_text(text)]\n",
    "    return docs\n",
    "\n",
    "\n",
    "# # create the open-source embedding function\n",
    "embeddings = OllamaEmbeddings(model=\"llama3\")\n",
    "docs = get_text_chunks_langchain(formatted_messages)\n",
    "# # load it into Chroma\n",
    "db2 = Chroma.from_documents(docs, embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # query it\n",
    "query = \"What is the name AusBoss's girl?\"\n",
    "docs = db2.similarity_search(query)\n",
    "\n",
    "# # print results\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
